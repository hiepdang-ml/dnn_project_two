{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "009e8fc2",
   "metadata": {},
   "source": [
    "# Dog Heart Vertebral Heart Size Point Detection \n",
    "# 1. Build an object detection model using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133be475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the code carefully!\n",
    "class DogHeartDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"Images\"))))\n",
    "        self.points = list(sorted(os.listdir(os.path.join(root, \"Labels\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = os.path.join(self.root, \"Images\", self.imgs[idx])\n",
    "        points_path = os.path.join(self.root, \"Labels\", self.points[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = img.size\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        h_new, w_new = img.shape[1], img.shape[2]\n",
    "        mat = loadmat(points_path)\n",
    "        six_points = mat['six_points'].astype(float)\n",
    "        six_points = torch.as_tensor(six_points, dtype=torch.float32)\n",
    "        six_points[:,0] = w_new/w*six_points[:,0] # Resize image to any size and maintain original points\n",
    "        six_points[:,1] = h_new/h*six_points[:,1]\n",
    "        six_points = torch.reshape(six_points, (-1,))/h_new # Normlize the points\n",
    "        VHS = mat['VHS'].astype(float)\n",
    "        VHS  = torch.as_tensor(VHS, dtype=torch.float32)\n",
    "        return img, six_points, VHS\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "\n",
    "def get_transform(resized_image_size):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    transforms.append(T.Resize(size = (resized_image_size,resized_image_size)))\n",
    "    transforms.append(T.Normalize(mean = [0.485,0.456,0.406], std = [0.229, 0.224, 0.225]))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "## Read Train dataset using the dataloader\n",
    "resized_image_size = 512\n",
    "dataset_train = DogHeartDataset('Dog_data/Train', get_transform(resized_image_size))\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "\n",
    "## Get origial image size and return predicted points back to original points size\n",
    "w, h = img.size\n",
    "# Make predictions using trained model\n",
    "points = model(img)*resized_image_size\n",
    "points = torch.reshape(points, (-1, 2))\n",
    "points[:,0] = w/resized_image_size*points[:,0]\n",
    "points[:,1] = h/resized_image_size*points[:,1]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0c45b84",
   "metadata": {},
   "source": [
    "# 2. Train your model using [Dog VHS Dataset](https://yuad-my.sharepoint.com/:f:/g/personal/youshan_zhang_yu_edu/ErguFJBE4y9KqzEdWWNlXzMBkTbsBaNX9l856SyvQauwJg?e=L3JOuN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50effdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f63262f",
   "metadata": {},
   "source": [
    "# 3.Evaluate your model using the test images with the [software](https://github.com/YoushanZhang/Dog-Cardiomegaly_VHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687038bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b5846bc",
   "metadata": {},
   "source": [
    "# 4. Your results should be achieved 85%. VHS = 6(AB+CD)/EF\n",
    "\n",
    "## (10 points, accuracy < 75% --> 0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a626823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e96710d9",
   "metadata": {},
   "source": [
    "# 5. Show the comprison between predictions and ground truth\n",
    "## You need to add the title with: image name, predicted VHS and Ground Truth VHS\n",
    "<p align=\"center\">\n",
    "  <img src=\"Com.png\" width=\"60%\"> \n",
    "</p>\n",
    "\n",
    "\n",
    "# Please show the comprison results of images: 1420.png, 1479.png and 1530.png from Valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44739b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62f12835",
   "metadata": {},
   "source": [
    "# 6. Write a three-page report using LaTex and upload your paper to ResearchGate or Arxiv, and put your paper link here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c16b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56b1a959",
   "metadata": {},
   "source": [
    "# 7. Grading rubric\n",
    "\n",
    "(1). Code ------- 20 points (you also need to upload your final model as a pt file, prediction CSV file and add paper link)\n",
    "\n",
    "(2). Grammer ---- 20 points\n",
    "\n",
    "(3). Introduction & related work --- 10 points\n",
    "\n",
    "(4). Method  ---- 20 points\n",
    "\n",
    "(5). Results ---- 20 points\n",
    "\n",
    "(6). Discussion - 10 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeee384",
   "metadata": {},
   "source": [
    "# 8. Bonus points (10 points if your accuracy is higer than 87.3%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75c46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
